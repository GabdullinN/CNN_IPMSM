{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is created\n"
     ]
    }
   ],
   "source": [
    "### This file containes codes written as part of the research \"Towards End-to-end Deep Learning Analysis of Electrical Machines\"\n",
    "### The manuscript is available at:\n",
    "### https://www.techrxiv.org/articles/preprint/Towards_End-to-end_Deep_Learning_Analysis_of_Electrical_Machines/13134932/1\n",
    "### The datasets are available at:\n",
    "### https://data.mendeley.com/datasets/j7bbrmmn4k/1\n",
    "\n",
    "### Codes here are set up to work with datasets that have \"average torque\" data\n",
    "### For torque curve datasets please see another file\n",
    "\n",
    "### Because CNNs trained on average torque datasets performed relatively poorly, this file does not contain a data visualization section\n",
    "### Please refer to other files for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is created\n"
     ]
    }
   ],
   "source": [
    "### Custom shallow 3-layer network\n",
    "\n",
    "import os, os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "img_size = 56\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5) \n",
    "\n",
    "        x = torch.randn(img_size,img_size).view(-1,1,img_size,img_size) \n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2)) \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.fc2(x)\n",
    "        return x \n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "print(\"model is created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ResNet\n",
    "\n",
    "import os, os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, intermediate_channels, identity_downsample=None, stride=1):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_channels, intermediate_channels, kernel_size = 1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(intermediate_channels, intermediate_channels, \n",
    "                               kernel_size = 3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(intermediate_channels, intermediate_channels*self.expansion, \n",
    "                               kernel_size = 1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "        \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, layers[0], intermediate_channels = 64, stride=1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], intermediate_channels = 128, stride = 2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], intermediate_channels = 256, stride = 2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], intermediate_channels = 512, stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*4, kernel_size=1,\n",
    "                                                          stride=stride),\n",
    "                                                nn.BatchNorm2d(intermediate_channels*4))\n",
    "        \n",
    "        layers.append(block(self.in_channels, intermediate_channels, identity_downsample, stride))      \n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "def ResNet50(img_channel=1,num_classes=1):\n",
    "    num_classes = num_classes\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = ResNet50(img_channel=1,num_classes=1).to(device)\n",
    "\n",
    "print(\"model is created\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all, training, val lengths:  4054 3244 810\n",
      "data is loaded\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = f\"model-{int(time.time())}\"\n",
    "\n",
    "all_data = np.load(\"56_average_cust_norm.npy\", allow_pickle=True)\n",
    "\n",
    "VAL_PCT = 0.2\n",
    "val_size = int(len(all_data)*VAL_PCT)\n",
    "\n",
    "training_data = all_data[:-val_size].tolist()\n",
    "validation_data = all_data[-val_size:].tolist()\n",
    "print(\"all, training, val lengths: \", len(all_data),len(training_data),len(validation_data))\n",
    "\n",
    "loader_train = DataLoader(training_data, batch_size=64,num_workers=0,pin_memory = True)\n",
    "loader_val = DataLoader(validation_data, batch_size=8,num_workers=0,pin_memory = True)\n",
    "\n",
    "img_size = 56\n",
    "\n",
    "print(\"data is loaded\")\n",
    "\n",
    "log_val_acc = []\n",
    "log_val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions have been defined\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[70,140,190], gamma=0.1)\n",
    "loss_function = nn.MSELoss()     \n",
    "\n",
    "def fwd_pass(X, y, train=False):\n",
    "\n",
    "    if train:\n",
    "        net.zero_grad() \n",
    "    outputs = net(X)\n",
    "    error = [abs(abs(i)-abs(j)) / abs(j) for i, j in zip(outputs, y)]\n",
    "    for ind,er in enumerate(error):\n",
    "        if er > 1:\n",
    "            error[ind] = 1\n",
    "        elif er < 0:\n",
    "            error[ind] = 0\n",
    "    acc = 1 - sum(error)/len(error)\n",
    "    loss = loss_function(outputs, y) #computes losses\n",
    "    \n",
    "    loss = loss * 100\n",
    "    \n",
    "    if train:\n",
    "        loss.backward() #backprop\n",
    "        optimizer.step() #runs the optimizer\n",
    "\n",
    "    return acc, loss\n",
    "\n",
    "def train(net):\n",
    "    BATCH_SIZE = 8\n",
    "    EPOCHS = 202\n",
    "\n",
    "    with open(\"model.log\", \"a\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "            #print(\"current epoch: \", epoch)\n",
    "            if (epoch+1)%1000 == 0:\n",
    "                print(\"training {}th epoch(+1)\".format(epoch+1))\n",
    "                val_acc, val_loss = test(size=BATCH_SIZE)\n",
    "                print(val_acc, val_loss)\n",
    "                log_val_acc.append(val_acc)\n",
    "                log_val_loss.append(val_loss)\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"checking learning rate! epoch {}, lr {}\".format(epoch, param_group['lr']))\n",
    "                    \n",
    "            if epoch == 0 or epoch%5 == 0 or epoch == (EPOCHS-1):\n",
    "                torch.save(net.state_dict(), \"model_states/state_ResNet_meany_normy_epoch_{}.pt\".format(epoch+1))\n",
    "            \n",
    "            for i, data in enumerate(tqdm(loader_train)):\n",
    "                \n",
    "                batch_X = data[0]\n",
    "                batch_y = data[1]\n",
    "                \n",
    "                batch_X = batch_X.view(-1,1,img_size,img_size)\n",
    "                batch_y = batch_y.view(-1,1)\n",
    "\n",
    "                batch_X, batch_y = batch_X.to(device, dtype=torch.float), batch_y.to(device)\n",
    "\n",
    "                acc, loss = fwd_pass(batch_X, batch_y, train=True) #.detach().item() \n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    val_acc, val_loss = test(size=BATCH_SIZE)\n",
    "                    f.write(f\"{MODEL_NAME},{round(time.time(),3)},{round(float(acc),2)},{round(float(loss), 4)},{round(float(val_acc),2)},{round(float(val_loss),4)}\\n\")\n",
    "            \n",
    "            if (epoch+1)%5 == 0:\n",
    "                print(\"training loss in {}th epoch(+1)\".format(epoch+1))\n",
    "                print(acc, loss)\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"checking learning rate! epoch {}, lr {}\".format(epoch, param_group['lr']))\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "def test(size=8):\n",
    "    BATCH_SIZE = size\n",
    "    X = torch.Tensor([i[0] for i in validation_data[:BATCH_SIZE]])\n",
    "    y = torch.Tensor([i[1] for i in validation_data[:BATCH_SIZE]]) \n",
    "    X = X.view(-1,1,img_size,img_size).to(device, dtype = torch.float)\n",
    "    y = y.view(-1,1).to(device)\n",
    "    val_acc, val_loss = fwd_pass(X, y)\n",
    "   \n",
    "    return val_acc, val_loss\n",
    "\n",
    "print(\"functions have been defined\")\n",
    "\n",
    "#lines below are only for validation on a previously trained CNN with parameters stored in a file \"dictionary_name.pt\"\n",
    "\n",
    "#net.load_state_dict(torch.load(\"dictionary_name.pt\",map_location=\"cuda:0\"))\n",
    "#net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 36/51 [00:02<00:00, 16.23it/s]"
     ]
    }
   ],
   "source": [
    "train(net)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking 0'th sample\n",
      "checking 500'th sample\n",
      "checking 1000'th sample\n",
      "checking 1500'th sample\n",
      "checking 2000'th sample\n",
      "checking 2500'th sample\n",
      "checking 3000'th sample\n",
      "training accuracy: 0.5879950818301979\n"
     ]
    }
   ],
   "source": [
    "### TRAINING DATA ACCURACY CHECK ###\n",
    "\n",
    "all_train = [None] *len(training_data)\n",
    "\n",
    "for check_one in range(len(training_data)):\n",
    "    if check_one%500 == 0:\n",
    "        print(\"checking {}'th sample\".format(check_one))\n",
    "    X_one = torch.Tensor(training_data[check_one][0]) \n",
    "    y_net = net(X_one.view(-1, 1, img_size, img_size).to(device))[0]\n",
    "    y_one = torch.Tensor([i[1] for i in training_data[check_one:check_one+2]]).to(device)  \n",
    "    \n",
    "    error = abs(torch.mean(y_net-y_one)) / torch.mean(y_one) \n",
    "    error = error.cpu().detach().numpy()\n",
    "\n",
    "    if error > 1:\n",
    "        error = 1\n",
    "    elif error < 0:\n",
    "        error = 0\n",
    "\n",
    "    acc = 1 - error\n",
    "    \n",
    "    y_net = y_net.cpu().detach().numpy() #another modification to use numpy \n",
    "    y_one = y_one.cpu().detach().numpy()\n",
    "    \n",
    "    all_train[check_one] = acc\n",
    "    \n",
    "acc_train = sum(all_train)/len(all_train)\n",
    "\n",
    "print(\"training accuracy:\",acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3244\n",
      "{0.1: 1576, 0.5: 1660, 2.5: 8, 10: 0}\n"
     ]
    }
   ],
   "source": [
    "### Checking the distribution of errors\n",
    "\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "counter = {0.1: 0, 0.5: 0, 2.5:0, 10:0 }\n",
    "print(len(y))\n",
    "for ans in y:\n",
    "    if ans < 0.2:\n",
    "        counter[0.1] +=1\n",
    "    if ans > 0.2 and ans <1:\n",
    "        counter[0.5] += 1\n",
    "    if ans > 1 and ans <5:\n",
    "        counter[2.5] += 1\n",
    "    if ans > 5:\n",
    "        counter[10] += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
